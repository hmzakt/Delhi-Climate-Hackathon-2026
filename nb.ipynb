{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c6f10a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c356535f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9aee8889",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      " OpenAQ v3: Fetching PM2.5 Data for Delhi\n",
      "======================================================================\n",
      "\n",
      "1. Fetching Delhi locations...\n",
      "   Found 4 Delhi locations\n",
      "\n",
      "1. Delhi Technological University, Delhi - CPCB (ID: 13)\n",
      "   Found 1 PM2.5 sensor(s)\n",
      "   - Sensor 13864: pm25 Âµg/mÂ³\n",
      "     Last data: 2018-02-22T04:00:00Z\n",
      "     âš  Sensor data too old, skipping\n",
      "2. R K Puram, Delhi - DPCC (ID: 17)\n",
      "   Found 2 PM2.5 sensor(s)\n",
      "   - Sensor 35: pm25 Âµg/mÂ³\n",
      "     Last data: 2018-02-21T21:15:00Z\n",
      "     âš  Sensor data too old, skipping\n",
      "   - Sensor 12234787: pm25 Âµg/mÂ³\n",
      "     Last data: 2026-02-14T08:30:00Z\n",
      "     Fetching hourly data...\n",
      "      Sample result structure: {\n",
      "  \"value\": 110.0,\n",
      "  \"flagInfo\": {\n",
      "    \"hasFlags\": false\n",
      "  },\n",
      "  \"parameter\": {\n",
      "    \"id\": 2,\n",
      "    \"name\": \"pm25\",\n",
      "    \"units\": \"\\u00b5g/m\\u00b3\",\n",
      "    \"displayName\": null\n",
      "  },\n",
      "  \"period\": {\n",
      "    \"label\": \"1hour\",\n",
      "    \"interval\": \"01:00:00\",\n",
      "    \"datetimeFrom\": {\n",
      "      \"utc\": \"2025-02-18T19:30:00Z\",\n",
      "   \n",
      "     âœ“ Got 7762 hours\n",
      "3. Punjabi Bagh, Delhi - DPCC (ID: 50)\n",
      "   Found 2 PM2.5 sensor(s)\n",
      "   - Sensor 396: pm25 Âµg/mÂ³\n",
      "     Last data: 2018-02-21T21:15:00Z\n",
      "     âš  Sensor data too old, skipping\n",
      "   - Sensor 12234796: pm25 Âµg/mÂ³\n",
      "     Last data: 2026-02-14T08:30:00Z\n",
      "     Fetching hourly data...\n",
      "      Sample result structure: {\n",
      "  \"value\": 107.0,\n",
      "  \"flagInfo\": {\n",
      "    \"hasFlags\": false\n",
      "  },\n",
      "  \"parameter\": {\n",
      "    \"id\": 2,\n",
      "    \"name\": \"pm25\",\n",
      "    \"units\": \"\\u00b5g/m\\u00b3\",\n",
      "    \"displayName\": null\n",
      "  },\n",
      "  \"period\": {\n",
      "    \"label\": \"1hour\",\n",
      "    \"interval\": \"01:00:00\",\n",
      "    \"datetimeFrom\": {\n",
      "      \"utc\": \"2025-02-18T19:30:00Z\",\n",
      "   \n",
      "     âœ“ Got 7604 hours\n",
      "4. Income Tax Office, Delhi - CPCB (ID: 103)\n",
      "   Found 1 PM2.5 sensor(s)\n",
      "   - Sensor 13861: pm25 Âµg/mÂ³\n",
      "     Last data: 2018-02-22T03:45:00Z\n",
      "     âš  Sensor data too old, skipping\n",
      "\n",
      "======================================================================\n",
      "\n",
      "âœ… SUCCESS! Saved 15366 PM2.5 records to 'data\\delhi_pm25_openaq_v3_final.csv'\n",
      "======================================================================\n",
      "\n",
      "ðŸ“Š Data Summary:\n",
      "   Shape: (15366, 9)\n",
      "   Date range: 2025-02-18 19:30:00+00:00 to 2026-02-14 07:30:00+00:00\n",
      "   Unique locations: 2\n",
      "   Unique sensors: 2\n",
      "\n",
      "ðŸ“ˆ PM2.5 Statistics (Âµg/mÂ³):\n",
      "   count   : 15,366.00\n",
      "   mean    : 107.35\n",
      "   std     : 106.89\n",
      "   min     : 1.00\n",
      "   25%     : 38.30\n",
      "   50%     : 68.50\n",
      "   75%     : 142.00\n",
      "   max     : 1,750.00\n",
      "\n",
      "ðŸ“‹ Sample Data (first 10 rows):\n",
      "             location_name              datetime_utc   pm25\n",
      "0  R K Puram, Delhi - DPCC 2025-02-18 19:30:00+00:00  110.0\n",
      "1  R K Puram, Delhi - DPCC 2025-02-18 20:30:00+00:00   94.8\n",
      "2  R K Puram, Delhi - DPCC 2025-02-18 21:30:00+00:00   94.5\n",
      "3  R K Puram, Delhi - DPCC 2025-02-18 22:30:00+00:00  102.0\n",
      "4  R K Puram, Delhi - DPCC 2025-02-18 23:30:00+00:00   74.0\n",
      "5  R K Puram, Delhi - DPCC 2025-02-19 00:30:00+00:00   97.8\n",
      "6  R K Puram, Delhi - DPCC 2025-02-19 01:30:00+00:00  103.0\n",
      "7  R K Puram, Delhi - DPCC 2025-02-19 02:30:00+00:00   97.5\n",
      "8  R K Puram, Delhi - DPCC 2025-02-19 03:30:00+00:00   99.8\n",
      "9  R K Puram, Delhi - DPCC 2025-02-19 04:30:00+00:00   80.5\n",
      "\n",
      "ðŸ’¾ Full dataset saved to: data\\delhi_pm25_openaq_v3_final.csv\n"
     ]
    }
   ],
   "source": [
    "# OpenAQ v3 â€” Fetch Delhi PM2.5 data with proper datetime handling\n",
    "import requests\n",
    "import pandas as pd\n",
    "import time\n",
    "from datetime import datetime\n",
    "import json\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "API_KEY = os.getenv(\"API_KEY\")\n",
    "\n",
    "HEADERS = {\"X-API-Key\": API_KEY, \"Accept\": \"application/json\"}\n",
    "\n",
    "DATE_FROM = \"2024-12-15T00:00:00Z\"\n",
    "DATE_TO   = \"2025-02-14T23:59:59Z\"\n",
    "\n",
    "BASE = \"https://api.openaq.org/v3\"\n",
    "\n",
    "def get_delhi_locations():\n",
    "    \"\"\"Get Delhi locations\"\"\"\n",
    "    url = f\"{BASE}/locations\"\n",
    "    r = requests.get(url, headers=HEADERS, params={\"limit\": 100}, timeout=30)\n",
    "    r.raise_for_status()\n",
    "    locations = r.json().get(\"results\", [])\n",
    "    \n",
    "    delhi_locs = [\n",
    "        loc for loc in locations \n",
    "        if \"delhi\" in str(loc.get(\"name\", \"\")).lower()\n",
    "    ]\n",
    "    return delhi_locs\n",
    "\n",
    "def get_location_sensors(location_id):\n",
    "    \"\"\"Get all sensors for a location\"\"\"\n",
    "    url = f\"{BASE}/locations/{location_id}/sensors\"\n",
    "    r = requests.get(url, headers=HEADERS, params={\"limit\": 100}, timeout=30)\n",
    "    if r.status_code == 200:\n",
    "        return r.json().get(\"results\", [])\n",
    "    return []\n",
    "\n",
    "def fetch_sensor_hours(sensor_id, date_from, date_to):\n",
    "    \"\"\"Fetch hourly data for a sensor\"\"\"\n",
    "    url = f\"{BASE}/sensors/{sensor_id}/hours\"\n",
    "    all_data = []\n",
    "    page = 1\n",
    "    max_pages = 30\n",
    "    \n",
    "    while page <= max_pages:\n",
    "        params = {\n",
    "            \"date_from\": date_from,\n",
    "            \"date_to\": date_to,\n",
    "            \"limit\": 1000,\n",
    "            \"page\": page\n",
    "        }\n",
    "        \n",
    "        try:\n",
    "            r = requests.get(url, headers=HEADERS, params=params, timeout=30)\n",
    "            if r.status_code == 404:\n",
    "                break\n",
    "            r.raise_for_status()\n",
    "            \n",
    "            results = r.json().get(\"results\", [])\n",
    "            \n",
    "            # Debug: print first result structure\n",
    "            if page == 1 and results and len(all_data) == 0:\n",
    "                print(f\"      Sample result structure: {json.dumps(results[0], indent=2)[:300]}\")\n",
    "            \n",
    "            if not results:\n",
    "                break\n",
    "            \n",
    "            all_data.extend(results)\n",
    "            \n",
    "            if len(results) < 1000:\n",
    "                break\n",
    "            \n",
    "            page += 1\n",
    "            time.sleep(0.2)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"      Error: {e}\")\n",
    "            break\n",
    "    \n",
    "    return all_data\n",
    "\n",
    "# ------------------------------\n",
    "# Main pipeline\n",
    "# ------------------------------\n",
    "print(\"=\"*70)\n",
    "print(\" OpenAQ v3: Fetching PM2.5 Data for Delhi\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "try:\n",
    "    # Get Delhi locations\n",
    "    print(\"\\n1. Fetching Delhi locations...\")\n",
    "    locations = get_delhi_locations()\n",
    "    print(f\"   Found {len(locations)} Delhi locations\\n\")\n",
    "    \n",
    "    all_rows = []\n",
    "    \n",
    "    for idx, loc in enumerate(locations, 1):\n",
    "        loc_id = loc.get(\"id\")\n",
    "        loc_name = loc.get(\"name\")\n",
    "        coords = loc.get(\"coordinates\", {})\n",
    "        lat = coords.get(\"latitude\")\n",
    "        lon = coords.get(\"longitude\")\n",
    "        \n",
    "        print(f\"{idx}. {loc_name} (ID: {loc_id})\")\n",
    "        \n",
    "        # Get sensors for this location\n",
    "        sensors = get_location_sensors(loc_id)\n",
    "        \n",
    "        if not sensors:\n",
    "            print(f\"   - No sensors found\")\n",
    "            continue\n",
    "        \n",
    "        # Filter for PM2.5 sensors\n",
    "        pm25_sensors = [\n",
    "            s for s in sensors \n",
    "            if s.get(\"parameter\", {}).get(\"name\", \"\").lower() == \"pm25\"\n",
    "            or s.get(\"parameter\", {}).get(\"id\") == 2\n",
    "        ]\n",
    "        \n",
    "        if not pm25_sensors:\n",
    "            print(f\"   - Has {len(sensors)} sensors but no PM2.5\")\n",
    "            continue\n",
    "        \n",
    "        print(f\"   Found {len(pm25_sensors)} PM2.5 sensor(s)\")\n",
    "        \n",
    "        for sensor in pm25_sensors:\n",
    "            sensor_id = sensor.get(\"id\")\n",
    "            sensor_name = sensor.get(\"name\")\n",
    "            date_last = sensor.get(\"datetimeLast\", {}).get(\"utc\", \"unknown\")\n",
    "            \n",
    "            print(f\"   - Sensor {sensor_id}: {sensor_name}\")\n",
    "            print(f\"     Last data: {date_last}\")\n",
    "            \n",
    "            # Check if sensor has data in our date range\n",
    "            if date_last != \"unknown\":\n",
    "                last_date = datetime.fromisoformat(date_last.replace(\"Z\", \"+00:00\"))\n",
    "                target_start = datetime.fromisoformat(DATE_FROM.replace(\"Z\", \"+00:00\"))\n",
    "                \n",
    "                if last_date < target_start:\n",
    "                    print(f\"     âš  Sensor data too old, skipping\")\n",
    "                    continue\n",
    "            \n",
    "            # Fetch hourly data\n",
    "            print(f\"     Fetching hourly data...\")\n",
    "            hours = fetch_sensor_hours(sensor_id, DATE_FROM, DATE_TO)\n",
    "            \n",
    "            if hours:\n",
    "                print(f\"     âœ“ Got {len(hours)} hours\")\n",
    "                \n",
    "                for h in hours:\n",
    "                    # Extract datetime - try different field names\n",
    "                    dt_utc = None\n",
    "                    if \"datetime\" in h:\n",
    "                        dt = h[\"datetime\"]\n",
    "                        if isinstance(dt, dict):\n",
    "                            dt_utc = dt.get(\"utc\")\n",
    "                        else:\n",
    "                            dt_utc = dt\n",
    "                    elif \"period\" in h:\n",
    "                        period = h[\"period\"]\n",
    "                        if isinstance(period, dict):\n",
    "                            dt_utc = period.get(\"datetimeFrom\", {}).get(\"utc\") if isinstance(period.get(\"datetimeFrom\"), dict) else period.get(\"datetimeFrom\")\n",
    "                    \n",
    "                    all_rows.append({\n",
    "                        \"location_id\": loc_id,\n",
    "                        \"location_name\": loc_name,\n",
    "                        \"latitude\": lat,\n",
    "                        \"longitude\": lon,\n",
    "                        \"sensor_id\": sensor_id,\n",
    "                        \"datetime_utc\": dt_utc,\n",
    "                        \"pm25\": h.get(\"value\"),\n",
    "                        \"unit\": \"Âµg/mÂ³\",\n",
    "                        \"coverage_percent\": h.get(\"coverage\", {}).get(\"percentComplete\") if isinstance(h.get(\"coverage\"), dict) else None\n",
    "                    })\n",
    "            else:\n",
    "                print(\"     âœ— No data in date range\")\n",
    "        \n",
    "        time.sleep(0.3)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    \n",
    "    if all_rows:\n",
    "        df = pd.DataFrame(all_rows)\n",
    "        \n",
    "        # Parse datetime\n",
    "        df[\"datetime_utc\"] = pd.to_datetime(df[\"datetime_utc\"], utc=True, errors=\"coerce\")\n",
    "        \n",
    "        # Remove rows with missing data\n",
    "        df = df.dropna(subset=[\"pm25\"])\n",
    "        \n",
    "        # Sort\n",
    "        df = df.sort_values([\"location_id\", \"sensor_id\", \"datetime_utc\"]).reset_index(drop=True)\n",
    "        \n",
    "        # Create data folder if it doesn't exist\n",
    "        data_folder = Path(\"data\")\n",
    "        data_folder.mkdir(exist_ok=True)\n",
    "        \n",
    "        # Save\n",
    "        out_file = data_folder / \"delhi_pm25_openaq_v3_final.csv\"\n",
    "        df.to_csv(out_file, index=False)\n",
    "        \n",
    "        print(f\"\\nSUCCESS! Saved {len(df)} PM2.5 records to '{out_file}'\")\n",
    "        print(\"=\"*70)\n",
    "        print(f\"\\nData Summary:\")\n",
    "        print(f\"   Shape: {df.shape}\")\n",
    "        print(f\"   Date range: {df['datetime_utc'].min()} to {df['datetime_utc'].max()}\")\n",
    "        print(f\"   Unique locations: {df['location_id'].nunique()}\")\n",
    "        print(f\"   Unique sensors: {df['sensor_id'].nunique()}\")\n",
    "        \n",
    "        print(f\"\\nPM2.5 Statistics (Âµg/mÂ³):\")\n",
    "        stats = df['pm25'].describe()\n",
    "        for stat_name, value in stats.items():\n",
    "            print(f\"   {stat_name:8s}: {value:,.2f}\")\n",
    "        \n",
    "        print(f\"\\nSample Data (first 10 rows):\")\n",
    "        print(df.head(10)[['location_name', 'datetime_utc', 'pm25']].to_string())\n",
    "        \n",
    "        print(f\"\\nFull dataset saved to: {out_file}\")\n",
    "        \n",
    "    else:\n",
    "        print(\"\\nNo PM2.5 data found for the specified date range\")\n",
    "        print(f\"\\nDate range requested: {DATE_FROM} to {DATE_TO}\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"\\nError: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b2a06a47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>location_id</th>\n",
       "      <th>location_name</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>sensor_id</th>\n",
       "      <th>datetime_utc</th>\n",
       "      <th>pm25</th>\n",
       "      <th>unit</th>\n",
       "      <th>coverage_percent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17</td>\n",
       "      <td>R K Puram, Delhi - DPCC</td>\n",
       "      <td>28.563262</td>\n",
       "      <td>77.186937</td>\n",
       "      <td>12234787</td>\n",
       "      <td>2025-02-18 19:30:00+00:00</td>\n",
       "      <td>110.0</td>\n",
       "      <td>Âµg/mÂ³</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17</td>\n",
       "      <td>R K Puram, Delhi - DPCC</td>\n",
       "      <td>28.563262</td>\n",
       "      <td>77.186937</td>\n",
       "      <td>12234787</td>\n",
       "      <td>2025-02-18 20:30:00+00:00</td>\n",
       "      <td>94.8</td>\n",
       "      <td>Âµg/mÂ³</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17</td>\n",
       "      <td>R K Puram, Delhi - DPCC</td>\n",
       "      <td>28.563262</td>\n",
       "      <td>77.186937</td>\n",
       "      <td>12234787</td>\n",
       "      <td>2025-02-18 21:30:00+00:00</td>\n",
       "      <td>94.5</td>\n",
       "      <td>Âµg/mÂ³</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17</td>\n",
       "      <td>R K Puram, Delhi - DPCC</td>\n",
       "      <td>28.563262</td>\n",
       "      <td>77.186937</td>\n",
       "      <td>12234787</td>\n",
       "      <td>2025-02-18 22:30:00+00:00</td>\n",
       "      <td>102.0</td>\n",
       "      <td>Âµg/mÂ³</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17</td>\n",
       "      <td>R K Puram, Delhi - DPCC</td>\n",
       "      <td>28.563262</td>\n",
       "      <td>77.186937</td>\n",
       "      <td>12234787</td>\n",
       "      <td>2025-02-18 23:30:00+00:00</td>\n",
       "      <td>74.0</td>\n",
       "      <td>Âµg/mÂ³</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>17</td>\n",
       "      <td>R K Puram, Delhi - DPCC</td>\n",
       "      <td>28.563262</td>\n",
       "      <td>77.186937</td>\n",
       "      <td>12234787</td>\n",
       "      <td>2025-02-19 00:30:00+00:00</td>\n",
       "      <td>97.8</td>\n",
       "      <td>Âµg/mÂ³</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>17</td>\n",
       "      <td>R K Puram, Delhi - DPCC</td>\n",
       "      <td>28.563262</td>\n",
       "      <td>77.186937</td>\n",
       "      <td>12234787</td>\n",
       "      <td>2025-02-19 01:30:00+00:00</td>\n",
       "      <td>103.0</td>\n",
       "      <td>Âµg/mÂ³</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>17</td>\n",
       "      <td>R K Puram, Delhi - DPCC</td>\n",
       "      <td>28.563262</td>\n",
       "      <td>77.186937</td>\n",
       "      <td>12234787</td>\n",
       "      <td>2025-02-19 02:30:00+00:00</td>\n",
       "      <td>97.5</td>\n",
       "      <td>Âµg/mÂ³</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>17</td>\n",
       "      <td>R K Puram, Delhi - DPCC</td>\n",
       "      <td>28.563262</td>\n",
       "      <td>77.186937</td>\n",
       "      <td>12234787</td>\n",
       "      <td>2025-02-19 03:30:00+00:00</td>\n",
       "      <td>99.8</td>\n",
       "      <td>Âµg/mÂ³</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>17</td>\n",
       "      <td>R K Puram, Delhi - DPCC</td>\n",
       "      <td>28.563262</td>\n",
       "      <td>77.186937</td>\n",
       "      <td>12234787</td>\n",
       "      <td>2025-02-19 04:30:00+00:00</td>\n",
       "      <td>80.5</td>\n",
       "      <td>Âµg/mÂ³</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>17</td>\n",
       "      <td>R K Puram, Delhi - DPCC</td>\n",
       "      <td>28.563262</td>\n",
       "      <td>77.186937</td>\n",
       "      <td>12234787</td>\n",
       "      <td>2025-02-19 05:30:00+00:00</td>\n",
       "      <td>69.5</td>\n",
       "      <td>Âµg/mÂ³</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>17</td>\n",
       "      <td>R K Puram, Delhi - DPCC</td>\n",
       "      <td>28.563262</td>\n",
       "      <td>77.186937</td>\n",
       "      <td>12234787</td>\n",
       "      <td>2025-02-19 06:30:00+00:00</td>\n",
       "      <td>65.8</td>\n",
       "      <td>Âµg/mÂ³</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>17</td>\n",
       "      <td>R K Puram, Delhi - DPCC</td>\n",
       "      <td>28.563262</td>\n",
       "      <td>77.186937</td>\n",
       "      <td>12234787</td>\n",
       "      <td>2025-02-19 07:30:00+00:00</td>\n",
       "      <td>59.0</td>\n",
       "      <td>Âµg/mÂ³</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>17</td>\n",
       "      <td>R K Puram, Delhi - DPCC</td>\n",
       "      <td>28.563262</td>\n",
       "      <td>77.186937</td>\n",
       "      <td>12234787</td>\n",
       "      <td>2025-02-19 08:30:00+00:00</td>\n",
       "      <td>55.8</td>\n",
       "      <td>Âµg/mÂ³</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>17</td>\n",
       "      <td>R K Puram, Delhi - DPCC</td>\n",
       "      <td>28.563262</td>\n",
       "      <td>77.186937</td>\n",
       "      <td>12234787</td>\n",
       "      <td>2025-02-19 09:30:00+00:00</td>\n",
       "      <td>44.5</td>\n",
       "      <td>Âµg/mÂ³</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>17</td>\n",
       "      <td>R K Puram, Delhi - DPCC</td>\n",
       "      <td>28.563262</td>\n",
       "      <td>77.186937</td>\n",
       "      <td>12234787</td>\n",
       "      <td>2025-02-19 10:30:00+00:00</td>\n",
       "      <td>37.3</td>\n",
       "      <td>Âµg/mÂ³</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>R K Puram, Delhi - DPCC</td>\n",
       "      <td>28.563262</td>\n",
       "      <td>77.186937</td>\n",
       "      <td>12234787</td>\n",
       "      <td>2025-02-19 11:30:00+00:00</td>\n",
       "      <td>31.8</td>\n",
       "      <td>Âµg/mÂ³</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>R K Puram, Delhi - DPCC</td>\n",
       "      <td>28.563262</td>\n",
       "      <td>77.186937</td>\n",
       "      <td>12234787</td>\n",
       "      <td>2025-02-19 12:30:00+00:00</td>\n",
       "      <td>47.0</td>\n",
       "      <td>Âµg/mÂ³</td>\n",
       "      <td>75.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>17</td>\n",
       "      <td>R K Puram, Delhi - DPCC</td>\n",
       "      <td>28.563262</td>\n",
       "      <td>77.186937</td>\n",
       "      <td>12234787</td>\n",
       "      <td>2025-02-19 13:30:00+00:00</td>\n",
       "      <td>67.3</td>\n",
       "      <td>Âµg/mÂ³</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>17</td>\n",
       "      <td>R K Puram, Delhi - DPCC</td>\n",
       "      <td>28.563262</td>\n",
       "      <td>77.186937</td>\n",
       "      <td>12234787</td>\n",
       "      <td>2025-02-19 14:30:00+00:00</td>\n",
       "      <td>89.3</td>\n",
       "      <td>Âµg/mÂ³</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    location_id            location_name   latitude  longitude  sensor_id  \\\n",
       "0            17  R K Puram, Delhi - DPCC  28.563262  77.186937   12234787   \n",
       "1            17  R K Puram, Delhi - DPCC  28.563262  77.186937   12234787   \n",
       "2            17  R K Puram, Delhi - DPCC  28.563262  77.186937   12234787   \n",
       "3            17  R K Puram, Delhi - DPCC  28.563262  77.186937   12234787   \n",
       "4            17  R K Puram, Delhi - DPCC  28.563262  77.186937   12234787   \n",
       "5            17  R K Puram, Delhi - DPCC  28.563262  77.186937   12234787   \n",
       "6            17  R K Puram, Delhi - DPCC  28.563262  77.186937   12234787   \n",
       "7            17  R K Puram, Delhi - DPCC  28.563262  77.186937   12234787   \n",
       "8            17  R K Puram, Delhi - DPCC  28.563262  77.186937   12234787   \n",
       "9            17  R K Puram, Delhi - DPCC  28.563262  77.186937   12234787   \n",
       "10           17  R K Puram, Delhi - DPCC  28.563262  77.186937   12234787   \n",
       "11           17  R K Puram, Delhi - DPCC  28.563262  77.186937   12234787   \n",
       "12           17  R K Puram, Delhi - DPCC  28.563262  77.186937   12234787   \n",
       "13           17  R K Puram, Delhi - DPCC  28.563262  77.186937   12234787   \n",
       "14           17  R K Puram, Delhi - DPCC  28.563262  77.186937   12234787   \n",
       "15           17  R K Puram, Delhi - DPCC  28.563262  77.186937   12234787   \n",
       "16           17  R K Puram, Delhi - DPCC  28.563262  77.186937   12234787   \n",
       "17           17  R K Puram, Delhi - DPCC  28.563262  77.186937   12234787   \n",
       "18           17  R K Puram, Delhi - DPCC  28.563262  77.186937   12234787   \n",
       "19           17  R K Puram, Delhi - DPCC  28.563262  77.186937   12234787   \n",
       "\n",
       "                 datetime_utc   pm25   unit  coverage_percent  \n",
       "0   2025-02-18 19:30:00+00:00  110.0  Âµg/mÂ³              50.0  \n",
       "1   2025-02-18 20:30:00+00:00   94.8  Âµg/mÂ³             100.0  \n",
       "2   2025-02-18 21:30:00+00:00   94.5  Âµg/mÂ³             100.0  \n",
       "3   2025-02-18 22:30:00+00:00  102.0  Âµg/mÂ³             100.0  \n",
       "4   2025-02-18 23:30:00+00:00   74.0  Âµg/mÂ³             100.0  \n",
       "5   2025-02-19 00:30:00+00:00   97.8  Âµg/mÂ³             100.0  \n",
       "6   2025-02-19 01:30:00+00:00  103.0  Âµg/mÂ³             100.0  \n",
       "7   2025-02-19 02:30:00+00:00   97.5  Âµg/mÂ³             100.0  \n",
       "8   2025-02-19 03:30:00+00:00   99.8  Âµg/mÂ³             100.0  \n",
       "9   2025-02-19 04:30:00+00:00   80.5  Âµg/mÂ³             100.0  \n",
       "10  2025-02-19 05:30:00+00:00   69.5  Âµg/mÂ³             100.0  \n",
       "11  2025-02-19 06:30:00+00:00   65.8  Âµg/mÂ³             100.0  \n",
       "12  2025-02-19 07:30:00+00:00   59.0  Âµg/mÂ³             100.0  \n",
       "13  2025-02-19 08:30:00+00:00   55.8  Âµg/mÂ³             100.0  \n",
       "14  2025-02-19 09:30:00+00:00   44.5  Âµg/mÂ³             100.0  \n",
       "15  2025-02-19 10:30:00+00:00   37.3  Âµg/mÂ³             100.0  \n",
       "16  2025-02-19 11:30:00+00:00   31.8  Âµg/mÂ³             100.0  \n",
       "17  2025-02-19 12:30:00+00:00   47.0  Âµg/mÂ³              75.0  \n",
       "18  2025-02-19 13:30:00+00:00   67.3  Âµg/mÂ³             100.0  \n",
       "19  2025-02-19 14:30:00+00:00   89.3  Âµg/mÂ³             100.0  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pm25df = pd.read_csv(\"data/delhi_pm25_openaq_v3_final.csv\")\n",
    "pm25df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "71f8a6be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requesting FIRMS Area CSV:\n",
      "https://firms.modaps.eosdis.nasa.gov/api/area/csv/fe917fc8c55db2e7396356bf5fbcb987/VIIRS_SNPP_NRT/74.0,27.0,79.5,31.5/5\n",
      "FIRMS area data saved to 'data/firms_area_fires_bbox.csv' with 230 rows.\n",
      "Columns saved: ['latitude', 'longitude', 'acq_date', 'acq_time', 'confidence', 'frp', 'instrument', 'satellite', 'acq_datetime']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>acq_date</th>\n",
       "      <th>acq_time</th>\n",
       "      <th>confidence</th>\n",
       "      <th>frp</th>\n",
       "      <th>instrument</th>\n",
       "      <th>satellite</th>\n",
       "      <th>acq_datetime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28.10806</td>\n",
       "      <td>78.52727</td>\n",
       "      <td>2026-02-10</td>\n",
       "      <td>0756</td>\n",
       "      <td>n</td>\n",
       "      <td>2.48</td>\n",
       "      <td>VIIRS</td>\n",
       "      <td>N</td>\n",
       "      <td>2026-02-10 07:56:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28.16176</td>\n",
       "      <td>77.61967</td>\n",
       "      <td>2026-02-10</td>\n",
       "      <td>0756</td>\n",
       "      <td>n</td>\n",
       "      <td>4.40</td>\n",
       "      <td>VIIRS</td>\n",
       "      <td>N</td>\n",
       "      <td>2026-02-10 07:56:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28.16256</td>\n",
       "      <td>77.47707</td>\n",
       "      <td>2026-02-10</td>\n",
       "      <td>0756</td>\n",
       "      <td>n</td>\n",
       "      <td>9.08</td>\n",
       "      <td>VIIRS</td>\n",
       "      <td>N</td>\n",
       "      <td>2026-02-10 07:56:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28.16378</td>\n",
       "      <td>77.61092</td>\n",
       "      <td>2026-02-10</td>\n",
       "      <td>0756</td>\n",
       "      <td>n</td>\n",
       "      <td>4.23</td>\n",
       "      <td>VIIRS</td>\n",
       "      <td>N</td>\n",
       "      <td>2026-02-10 07:56:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28.16445</td>\n",
       "      <td>77.61495</td>\n",
       "      <td>2026-02-10</td>\n",
       "      <td>0756</td>\n",
       "      <td>n</td>\n",
       "      <td>4.40</td>\n",
       "      <td>VIIRS</td>\n",
       "      <td>N</td>\n",
       "      <td>2026-02-10 07:56:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>28.16647</td>\n",
       "      <td>77.60617</td>\n",
       "      <td>2026-02-10</td>\n",
       "      <td>0756</td>\n",
       "      <td>n</td>\n",
       "      <td>4.75</td>\n",
       "      <td>VIIRS</td>\n",
       "      <td>N</td>\n",
       "      <td>2026-02-10 07:56:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>28.22840</td>\n",
       "      <td>78.11343</td>\n",
       "      <td>2026-02-10</td>\n",
       "      <td>0756</td>\n",
       "      <td>n</td>\n",
       "      <td>4.50</td>\n",
       "      <td>VIIRS</td>\n",
       "      <td>N</td>\n",
       "      <td>2026-02-10 07:56:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>28.32761</td>\n",
       "      <td>77.73525</td>\n",
       "      <td>2026-02-10</td>\n",
       "      <td>0756</td>\n",
       "      <td>n</td>\n",
       "      <td>2.98</td>\n",
       "      <td>VIIRS</td>\n",
       "      <td>N</td>\n",
       "      <td>2026-02-10 07:56:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>28.37817</td>\n",
       "      <td>77.80429</td>\n",
       "      <td>2026-02-10</td>\n",
       "      <td>0756</td>\n",
       "      <td>n</td>\n",
       "      <td>9.82</td>\n",
       "      <td>VIIRS</td>\n",
       "      <td>N</td>\n",
       "      <td>2026-02-10 07:56:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>28.41248</td>\n",
       "      <td>77.88796</td>\n",
       "      <td>2026-02-10</td>\n",
       "      <td>0756</td>\n",
       "      <td>n</td>\n",
       "      <td>2.37</td>\n",
       "      <td>VIIRS</td>\n",
       "      <td>N</td>\n",
       "      <td>2026-02-10 07:56:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   latitude  longitude    acq_date acq_time confidence   frp instrument  \\\n",
       "0  28.10806   78.52727  2026-02-10     0756          n  2.48      VIIRS   \n",
       "1  28.16176   77.61967  2026-02-10     0756          n  4.40      VIIRS   \n",
       "2  28.16256   77.47707  2026-02-10     0756          n  9.08      VIIRS   \n",
       "3  28.16378   77.61092  2026-02-10     0756          n  4.23      VIIRS   \n",
       "4  28.16445   77.61495  2026-02-10     0756          n  4.40      VIIRS   \n",
       "5  28.16647   77.60617  2026-02-10     0756          n  4.75      VIIRS   \n",
       "6  28.22840   78.11343  2026-02-10     0756          n  4.50      VIIRS   \n",
       "7  28.32761   77.73525  2026-02-10     0756          n  2.98      VIIRS   \n",
       "8  28.37817   77.80429  2026-02-10     0756          n  9.82      VIIRS   \n",
       "9  28.41248   77.88796  2026-02-10     0756          n  2.37      VIIRS   \n",
       "\n",
       "  satellite        acq_datetime  \n",
       "0         N 2026-02-10 07:56:00  \n",
       "1         N 2026-02-10 07:56:00  \n",
       "2         N 2026-02-10 07:56:00  \n",
       "3         N 2026-02-10 07:56:00  \n",
       "4         N 2026-02-10 07:56:00  \n",
       "5         N 2026-02-10 07:56:00  \n",
       "6         N 2026-02-10 07:56:00  \n",
       "7         N 2026-02-10 07:56:00  \n",
       "8         N 2026-02-10 07:56:00  \n",
       "9         N 2026-02-10 07:56:00  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# FIRMS Area API (uses MAP_KEY from env FIRMS_MAP_KEY)\n",
    "# - Uses endpoint: /api/area/csv/[MAP_KEY]/[SOURCE]/[AREA_COORDINATES]/[DAY_RANGE]\n",
    "# - AREA_COORDINATES = west,south,east,north (e.g. 74.0,27.0,79.5,31.5)\n",
    "# - DAY_RANGE must be 1..5 (days)\n",
    "# Replace bounding box or SOURCE as you like.\n",
    "\n",
    "import os\n",
    "import requests\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "\n",
    "# --------------------------\n",
    "# CONFIG (edit if needed)\n",
    "# --------------------------\n",
    "MAP_KEY_ENVVAR = \"FIRMS_MAP_KEY\"   # you said you added this to env\n",
    "SOURCE = \"VIIRS_SNPP_NRT\"          # Near-Real-Time VIIRS S-NPP (good for recent fires)\n",
    "# Bounding box: west, south, east, north  (Delhi + Punjab/Haryana/UP slice)\n",
    "AREA_COORDS = \"74.0,27.0,79.5,31.5\"\n",
    "DAY_RANGE = 5                       # must be between 1 and 5 (inclusive)\n",
    "OUT_CSV = \"data/firms_area_fires_bbox.csv\"\n",
    "BASE_URL = \"https://firms.modaps.eosdis.nasa.gov/api/area/csv\"\n",
    "\n",
    "# --------------------------\n",
    "# Sanity checks\n",
    "# --------------------------\n",
    "map_key = os.environ.get(MAP_KEY_ENVVAR)\n",
    "if not map_key:\n",
    "    raise EnvironmentError(\n",
    "        f\"Environment variable '{MAP_KEY_ENVVAR}' not found. \"\n",
    "        \"Set it to your FIRMS MAP_KEY and try again.\"\n",
    "    )\n",
    "\n",
    "if not (1 <= DAY_RANGE <= 5):\n",
    "    raise ValueError(\"DAY_RANGE must be between 1 and 5 (inclusive).\")\n",
    "\n",
    "# Build request URL\n",
    "# Format: /api/area/csv/[MAP_KEY]/[SOURCE]/[AREA_COORDINATES]/[DAY_RANGE]\n",
    "url = f\"{BASE_URL}/{map_key}/{SOURCE}/{AREA_COORDS}/{DAY_RANGE}\"\n",
    "\n",
    "print(\"Requesting FIRMS Area CSV:\")\n",
    "print(url)\n",
    "\n",
    "# Fetch\n",
    "resp = requests.get(url, timeout=60)\n",
    "if resp.status_code != 200:\n",
    "    # Helpful debugging info\n",
    "    raise RuntimeError(\n",
    "        f\"FIRMS API request failed: HTTP {resp.status_code}\\nResponse text:\\n{resp.text}\"\n",
    "    )\n",
    "\n",
    "# Parse CSV into pandas\n",
    "csv_text = resp.text\n",
    "df = pd.read_csv(StringIO(csv_text))\n",
    "\n",
    "# Optional: keep only recommended columns\n",
    "columns_to_keep = [\n",
    "    \"latitude\",\n",
    "    \"longitude\",\n",
    "    \"acq_date\",\n",
    "    \"acq_time\",\n",
    "    \"acq_datetime\",     # some CSVs include this; if not, we'll create it\n",
    "    \"confidence\",\n",
    "    \"frp\",\n",
    "    \"brightness\",\n",
    "    \"instrument\",\n",
    "    \"satellite\"\n",
    "]\n",
    "# Keep only available columns\n",
    "cols_present = [c for c in columns_to_keep if c in df.columns]\n",
    "df = df[cols_present].copy()\n",
    "\n",
    "# Ensure acq_datetime column exists (create from acq_date + acq_time if needed)\n",
    "if \"acq_datetime\" not in df.columns and {\"acq_date\", \"acq_time\"}.issubset(df.columns):\n",
    "    df[\"acq_time\"] = df[\"acq_time\"].astype(str).str.zfill(4)  # ensure HHMM\n",
    "    df[\"acq_datetime\"] = pd.to_datetime(df[\"acq_date\"] + \" \" + df[\"acq_time\"], format=\"%Y-%m-%d %H%M\", errors=\"coerce\")\n",
    "\n",
    "# Save cleaned CSV\n",
    "df.to_csv(OUT_CSV, index=False)\n",
    "print(f\"FIRMS area data saved to '{OUT_CSV}' with {len(df)} rows.\")\n",
    "print(\"Columns saved:\", df.columns.tolist())\n",
    "\n",
    "\n",
    "df.head(10)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.13.1)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
